{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled21.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPrN0eMbwsJaWim/wjw/qsu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dontbanmeplz/face-recognition/blob/main/Untitled21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnMKfbf7_4Ov",
        "outputId": "89d5b84b-9edb-4c65-b2c6-9464dc5bc054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'face-recognition'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 39 (delta 20), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (39/39), done.\n",
            "--2022-05-18 16:03:42--  https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 930127 (908K) [text/plain]\n",
            "Saving to: ‘haarcascade_frontalface_default.xml’\n",
            "\n",
            "haarcascade_frontal 100%[===================>] 908.33K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-05-18 16:03:42 (19.9 MB/s) - ‘haarcascade_frontalface_default.xml’ saved [930127/930127]\n",
            "\n",
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0+zzzcolab20220513001918)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 100.1 MB 23 kB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.21.6)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566186 sha256=9d4dfade85955212af775f4073e14eaa9d24f90a77739f3a63edc2728ee323f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/81/3c/884bcd5e1c120ff548d57c2ecc9ebf3281c9a6f7c0e7e7947a\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n",
            "[INFO] loading encodings...\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dontbanmeplz/face-recognition\n",
        "import os \n",
        "os.chdir(\"face-recognition\")\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "import html\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "def jsob_to_image(js_object):\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_object.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  img_array = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # convert numpy array into OpenCV BGR \n",
        "  frame = cv2.imdecode(img_array, flags=1)\n",
        "\n",
        "  return frame\n",
        "!wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
        "!mkdir faces\n",
        "!pip install face_recognition\n",
        "import recognize_faces_image as detect"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python build_face_dataset.py -i ../Luke.MOV -o faces/luke -c haarcascade_frontalface_default.xml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zucg58ORS4OW",
        "outputId": "383f6ac0-c625-4c93-e1b1-767ac94946ba"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] starting video stream...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python encode_faces.py --dataset faces --encodings encodings.pickle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkqnz18jYefB",
        "outputId": "809214b0-55b6-4901-c78b-dcc5325f7b74"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] quantifying faces...\n",
            "[INFO] processing image 1/104\n",
            "[INFO] processing image 2/104\n",
            "[INFO] processing image 3/104\n",
            "[INFO] processing image 4/104\n",
            "[INFO] processing image 5/104\n",
            "[INFO] processing image 6/104\n",
            "[INFO] processing image 7/104\n",
            "[INFO] processing image 8/104\n",
            "[INFO] processing image 9/104\n",
            "[INFO] processing image 10/104\n",
            "[INFO] processing image 11/104\n",
            "[INFO] processing image 12/104\n",
            "[INFO] processing image 13/104\n",
            "[INFO] processing image 14/104\n",
            "[INFO] processing image 15/104\n",
            "[INFO] processing image 16/104\n",
            "[INFO] processing image 17/104\n",
            "[INFO] processing image 18/104\n",
            "[INFO] processing image 19/104\n",
            "[INFO] processing image 20/104\n",
            "[INFO] processing image 21/104\n",
            "[INFO] processing image 22/104\n",
            "[INFO] processing image 23/104\n",
            "[INFO] processing image 24/104\n",
            "[INFO] processing image 25/104\n",
            "[INFO] processing image 26/104\n",
            "[INFO] processing image 27/104\n",
            "[INFO] processing image 28/104\n",
            "[INFO] processing image 29/104\n",
            "[INFO] processing image 30/104\n",
            "[INFO] processing image 31/104\n",
            "[INFO] processing image 32/104\n",
            "[INFO] processing image 33/104\n",
            "[INFO] processing image 34/104\n",
            "[INFO] processing image 35/104\n",
            "[INFO] processing image 36/104\n",
            "[INFO] processing image 37/104\n",
            "[INFO] processing image 38/104\n",
            "[INFO] processing image 39/104\n",
            "[INFO] processing image 40/104\n",
            "[INFO] processing image 41/104\n",
            "[INFO] processing image 42/104\n",
            "[INFO] processing image 43/104\n",
            "[INFO] processing image 44/104\n",
            "[INFO] processing image 45/104\n",
            "[INFO] processing image 46/104\n",
            "[INFO] processing image 47/104\n",
            "[INFO] processing image 48/104\n",
            "[INFO] processing image 49/104\n",
            "[INFO] processing image 50/104\n",
            "[INFO] processing image 51/104\n",
            "[INFO] processing image 52/104\n",
            "[INFO] processing image 53/104\n",
            "[INFO] processing image 54/104\n",
            "[INFO] processing image 55/104\n",
            "[INFO] processing image 56/104\n",
            "[INFO] processing image 57/104\n",
            "[INFO] processing image 58/104\n",
            "[INFO] processing image 59/104\n",
            "[INFO] processing image 60/104\n",
            "[INFO] processing image 61/104\n",
            "[INFO] processing image 62/104\n",
            "[INFO] processing image 63/104\n",
            "[INFO] processing image 64/104\n",
            "[INFO] processing image 65/104\n",
            "[INFO] processing image 66/104\n",
            "[INFO] processing image 67/104\n",
            "[INFO] processing image 68/104\n",
            "[INFO] processing image 69/104\n",
            "[INFO] processing image 70/104\n",
            "[INFO] processing image 71/104\n",
            "[INFO] processing image 72/104\n",
            "[INFO] processing image 73/104\n",
            "[INFO] processing image 74/104\n",
            "[INFO] processing image 75/104\n",
            "[INFO] processing image 76/104\n",
            "[INFO] processing image 77/104\n",
            "[INFO] processing image 78/104\n",
            "[INFO] processing image 79/104\n",
            "[INFO] processing image 80/104\n",
            "[INFO] processing image 81/104\n",
            "[INFO] processing image 82/104\n",
            "[INFO] processing image 83/104\n",
            "[INFO] processing image 84/104\n",
            "[INFO] processing image 85/104\n",
            "[INFO] processing image 86/104\n",
            "[INFO] processing image 87/104\n",
            "[INFO] processing image 88/104\n",
            "[INFO] processing image 89/104\n",
            "[INFO] processing image 90/104\n",
            "[INFO] processing image 91/104\n",
            "[INFO] processing image 92/104\n",
            "[INFO] processing image 93/104\n",
            "[INFO] processing image 94/104\n",
            "[INFO] processing image 95/104\n",
            "[INFO] processing image 96/104\n",
            "[INFO] processing image 97/104\n",
            "[INFO] processing image 98/104\n",
            "[INFO] processing image 99/104\n",
            "[INFO] processing image 100/104\n",
            "[INFO] processing image 101/104\n",
            "[INFO] processing image 102/104\n",
            "[INFO] processing image 103/104\n",
            "[INFO] processing image 104/104\n",
            "[INFO] serializing encodings...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python recognize_faces_image.py --encodings encodings.pickle --image ../image.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2ezi0-3Z6KI",
        "outputId": "bcfc70ab-6d98-42db-d42c-1c0b18e1600c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading encodings...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.style.position = \"relative\";\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"user\"}});\n",
        "      div.appendChild(video);\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      imgg = document.createElement('img');\n",
        "      imgg.id = \"image\";\n",
        "      imgg.width = 640;\n",
        "      imgg.hight = 480;\n",
        "      imgg.style.position = \"absolute\";\n",
        "      imgg.style.top = 0;\n",
        "      imgg.style.left = 0;\n",
        "      imgg.style.background = \"transparent\";\n",
        "      div.appendChild(imgg)\n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"blue: red; font-weight: bold;\">' +\n",
        "          'click here to stop the video</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; \n",
        "      captureCanvas.height = 480; \n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame() {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "  \n",
        "            \n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame():\n",
        "  data = eval_js('stream_frame()')\n",
        "  return data"
      ],
      "metadata": {
        "id": "yD94HGLi7-n6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "import face_recognition\n",
        "import argparse\n",
        "import pickle\n",
        "import cv2, time\n",
        "# construct the argument parser and parse the arguments\n",
        "\n",
        "'''ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-e\", \"--encodings\", required=True,\n",
        "\thelp=\"path to serialized db of facial encodings\")\n",
        "ap.add_argument(\"-i\", \"--image\", required=True,\n",
        "\thelp=\"path to input image\")\n",
        "ap.add_argument(\"-d\", \"--detection-method\", type=str, default=\"cnn\",\n",
        "\thelp=\"face detection model to use: either `hog` or `cnn`\")\n",
        "args = vars(ap.parse_args())'''\n",
        "# load the known faces and embeddings\n",
        "print(\"[INFO] loading encodings...\")\n",
        "class detect:\n",
        "  def __init__(self):\n",
        "    self.data = pickle.loads(open(\"encodings.pickle\", \"rb\").read())\n",
        "  def go(self, image):\n",
        "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    #print(\"[INFO] recognizing faces...\")\n",
        "    t = time.time()\n",
        "    boxes = face_recognition.face_locations(rgb,\n",
        "\t  model=\"hog\")\n",
        "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
        "    # initialize the list of names for each face detected\n",
        "    names = []\n",
        "    # loop over the facial embeddings\n",
        "    for encoding in encodings:\n",
        "      # attempt to match each face in the input image to our known\n",
        "      # encodings\n",
        "      name = \"Unknown\"\n",
        "      matches = face_recognition.compare_faces(self.data[\"encodings\"],\n",
        "        encoding)\n",
        "      # check to see if we have found a match\n",
        "      if True in matches:\n",
        "        # find the indexes of all matched faces then initialize a\n",
        "        # dictionary to count the total number of times each face\n",
        "        # was matched\n",
        "        matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
        "        counts = {}\n",
        "        # loop over the matched indexes and maintain a count for\n",
        "        # each recognized face face\n",
        "        for i in matchedIdxs:\n",
        "          name = self.data[\"names\"][i]\n",
        "          counts[name] = counts.get(name, 0) + 1\n",
        "        # determine the recognized face with the largest number of\n",
        "        \n",
        "        # votes (note: in the event of an unlikely tie Python will\n",
        "        \n",
        "        # select first entry in the dictionary)\n",
        "        \n",
        "        name = max(counts, key=counts.get)\n",
        "      \n",
        "      # update the list of names\n",
        "      names.append(name)\n",
        "      name = \"Unknown\"\n",
        "    #mask = np.zeros((150, 300, 4), dtype=np.uint8)\n",
        "    # loop over the recognized faces\n",
        "    for ((top, right, bottom, left), name) in zip(boxes, names):\n",
        "      # draw the predicted face name on the image\n",
        "      cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
        "      y = top - 15 if top - 15 > 15 else top + 15\n",
        "      cv2.putText(image, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        0.75, (0, 255, 0), 2)\n",
        "    return image\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOGh2DvHGiHG",
        "outputId": "3b611535-6714-4f1a-eee3-f47462f892fe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading encodings...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_stream()\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output\n",
        "import base64\n",
        "det = detect()\n",
        "while True:\n",
        "    frame_js = video_frame()\n",
        "    if not frame_js:\n",
        "        break\n",
        "    img = jsob_to_image(frame_js[\"img\"])\n",
        "    img = det.go(img)\n",
        "    retval, buffer_img= cv2.imencode('.jpg', img)\n",
        "    data = base64.b64encode(buffer_img)\n",
        "    t = time.time()\n",
        "    data = data.decode()\n",
        "    print(\"decode\")\n",
        "    print(time.time()-t)\n",
        "    data = \"data:image/jpg;base64,\" + data\n",
        "    eval_js(\"document.getElementById('image').src = '\" + data + \"'\")\n",
        "    #cv2_imshow(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wNS2hoPO8AzI",
        "outputId": "de5d1f59-4c72-4d8b-c075-7fec1cc58c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.style.position = \"relative\";\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"user\"}});\n",
              "      div.appendChild(video);\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      imgg = document.createElement('img');\n",
              "      imgg.id = \"image\";\n",
              "      imgg.width = 640;\n",
              "      imgg.hight = 480;\n",
              "      imgg.style.position = \"absolute\";\n",
              "      imgg.style.top = 0;\n",
              "      imgg.style.left = 0;\n",
              "      imgg.style.background = \"transparent\";\n",
              "      div.appendChild(imgg)\n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"blue: red; font-weight: bold;\">' +\n",
              "          'click here to stop the video</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640; \n",
              "      captureCanvas.height = 480; \n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame() {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "  \n",
              "            \n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decode\n",
            "0.0006616115570068359\n",
            "decode\n",
            "0.00011444091796875\n",
            "decode\n",
            "0.0001423358917236328\n",
            "decode\n",
            "0.00012087821960449219\n",
            "decode\n",
            "0.00011968612670898438\n",
            "decode\n",
            "0.0001266002655029297\n",
            "decode\n",
            "0.00012993812561035156\n",
            "decode\n",
            "0.00012063980102539062\n",
            "decode\n",
            "0.00012135505676269531\n",
            "decode\n",
            "0.00014090538024902344\n",
            "decode\n",
            "0.00011301040649414062\n",
            "decode\n",
            "0.00011348724365234375\n",
            "decode\n",
            "0.0001270771026611328\n",
            "decode\n",
            "0.00012922286987304688\n",
            "decode\n",
            "0.00011944770812988281\n",
            "decode\n",
            "0.00012087821960449219\n"
          ]
        }
      ]
    }
  ]
}